{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CycleGAN for Image-to-Image Translation\n",
        "\n",
        "<!--\n",
        "Project: CycleGAN for Image-to-Image Translation\n",
        "Author: RSK World\n",
        "Website: https://rskworld.in\n",
        "Email: help@rskworld.in\n",
        "Phone: +91 93305 39277\n",
        "Description: CycleGAN for unpaired image-to-image translation using cycle-consistent adversarial networks\n",
        "-->\n",
        "\n",
        "This notebook demonstrates the CycleGAN model for unpaired image-to-image translation.\n",
        "\n",
        "## Features\n",
        "- Unpaired image translation\n",
        "- Cycle consistency loss\n",
        "- Style transfer capabilities\n",
        "- No need for paired training data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "# Author: RSK World\n",
        "# Website: https://rskworld.in\n",
        "# Email: help@rskworld.in\n",
        "# Phone: +91 93305 39277\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add project root to path\n",
        "sys.path.append(os.path.dirname(os.getcwd()))\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load the CycleGAN Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load CycleGAN model\n",
        "# Author: RSK World\n",
        "# Website: https://rskworld.in\n",
        "\n",
        "from models import CycleGANModel\n",
        "from models.networks import define_G\n",
        "import argparse\n",
        "\n",
        "# Create a simple config object\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.input_nc = 3\n",
        "        self.output_nc = 3\n",
        "        self.ngf = 64\n",
        "        self.ndf = 64\n",
        "        self.netG = 'resnet_9blocks'\n",
        "        self.netD = 'basic'\n",
        "        self.n_layers_D = 3\n",
        "        self.norm = 'instance'\n",
        "        self.init_type = 'normal'\n",
        "        self.init_gain = 0.02\n",
        "        self.no_dropout = True\n",
        "        self.gpu_ids = [0] if torch.cuda.is_available() else []\n",
        "        self.isTrain = False\n",
        "        self.lambda_A = 10.0\n",
        "        self.lambda_B = 10.0\n",
        "        self.lambda_identity = 0.5\n",
        "        self.pool_size = 50\n",
        "        self.checkpoints_dir = './checkpoints'\n",
        "        self.name = 'cyclegan_experiment'\n",
        "        self.epoch = 'latest'\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Define generator\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "netG_A2B = define_G(config.input_nc, config.output_nc, config.ngf, config.netG, \n",
        "                     config.norm, not config.no_dropout, config.init_type, \n",
        "                     config.init_gain, config.gpu_ids)\n",
        "netG_B2A = define_G(config.output_nc, config.input_nc, config.ngf, config.netG, \n",
        "                     config.norm, not config.no_dropout, config.init_type, \n",
        "                     config.init_gain, config.gpu_ids)\n",
        "\n",
        "netG_A2B.to(device)\n",
        "netG_B2A.to(device)\n",
        "netG_A2B.eval()\n",
        "netG_B2A.eval()\n",
        "\n",
        "print(\"Generators loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Image Preprocessing Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image preprocessing functions\n",
        "# Author: RSK World\n",
        "# Website: https://rskworld.in\n",
        "\n",
        "def preprocess_image(image_path, size=256):\n",
        "    \"\"\"\n",
        "    Preprocess an image for CycleGAN.\n",
        "    \n",
        "    Args:\n",
        "        image_path: Path to the image\n",
        "        size: Target size for the image\n",
        "        \n",
        "    Returns:\n",
        "        Preprocessed tensor\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(size),\n",
        "        transforms.CenterCrop(size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    \n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_tensor = transform(image).unsqueeze(0)\n",
        "    return image_tensor\n",
        "\n",
        "def tensor_to_image(tensor):\n",
        "    \"\"\"\n",
        "    Convert a tensor to a PIL Image.\n",
        "    \n",
        "    Args:\n",
        "        tensor: Input tensor\n",
        "        \n",
        "    Returns:\n",
        "        PIL Image\n",
        "    \"\"\"\n",
        "    tensor = tensor.squeeze(0).cpu()\n",
        "    tensor = (tensor + 1) / 2.0\n",
        "    tensor = torch.clamp(tensor, 0, 1)\n",
        "    to_pil = transforms.ToPILImage()\n",
        "    return to_pil(tensor)\n",
        "\n",
        "print(\"Preprocessing functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Image Translation Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image translation function\n",
        "# Author: RSK World\n",
        "# Website: https://rskworld.in\n",
        "\n",
        "def translate_image(image_path, direction='AtoB'):\n",
        "    \"\"\"\n",
        "    Translate an image using CycleGAN.\n",
        "    \n",
        "    Args:\n",
        "        image_path: Path to the input image\n",
        "        direction: Translation direction ('AtoB' or 'BtoA')\n",
        "        \n",
        "    Returns:\n",
        "        Translated image as PIL Image\n",
        "    \"\"\"\n",
        "    # Preprocess image\n",
        "    image_tensor = preprocess_image(image_path)\n",
        "    image_tensor = image_tensor.to(device)\n",
        "    \n",
        "    # Translate\n",
        "    with torch.no_grad():\n",
        "        if direction == 'AtoB':\n",
        "            translated = netG_A2B(image_tensor)\n",
        "        else:\n",
        "            translated = netG_B2A(image_tensor)\n",
        "    \n",
        "    # Convert back to image\n",
        "    result_image = tensor_to_image(translated)\n",
        "    return result_image\n",
        "\n",
        "print(\"Translation function defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualization Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization function\n",
        "# Author: RSK World\n",
        "# Website: https://rskworld.in\n",
        "\n",
        "def visualize_translation(image_path, direction='AtoB'):\n",
        "    \"\"\"\n",
        "    Visualize the translation result.\n",
        "    \n",
        "    Args:\n",
        "        image_path: Path to the input image\n",
        "        direction: Translation direction\n",
        "    \"\"\"\n",
        "    # Load original image\n",
        "    original = Image.open(image_path).convert('RGB')\n",
        "    \n",
        "    # Translate\n",
        "    translated = translate_image(image_path, direction)\n",
        "    \n",
        "    # Display\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    axes[0].imshow(original)\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    axes[1].imshow(translated)\n",
        "    axes[1].set_title(f'Translated Image ({direction})')\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Visualization function defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Example Usage\n",
        "\n",
        "To use this notebook:\n",
        "\n",
        "1. Prepare your dataset in the following structure:\n",
        "   ```\n",
        "   datasets/\n",
        "   └── your_dataset/\n",
        "       ├── trainA/  # Domain A images\n",
        "       ├── trainB/  # Domain B images\n",
        "       ├── testA/   # Test images from domain A\n",
        "       └── testB/   # Test images from domain B\n",
        "   ```\n",
        "\n",
        "2. Train the model using:\n",
        "   ```bash\n",
        "   python train.py --dataroot ./datasets/your_dataset --name experiment_name\n",
        "   ```\n",
        "\n",
        "3. Load a trained model and test:\n",
        "   ```python\n",
        "   # Example: Translate an image\n",
        "   image_path = './datasets/your_dataset/testA/image1.jpg'\n",
        "   visualize_translation(image_path, direction='AtoB')\n",
        "   ```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Cycle Consistency Demonstration\n",
        "\n",
        "This section demonstrates the cycle consistency property of CycleGAN.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cycle consistency demonstration\n",
        "# Author: RSK World\n",
        "# Website: https://rskworld.in\n",
        "\n",
        "def demonstrate_cycle_consistency(image_path):\n",
        "    \"\"\"\n",
        "    Demonstrate cycle consistency: A -> B -> A should be close to original A.\n",
        "    \n",
        "    Args:\n",
        "        image_path: Path to the input image\n",
        "    \"\"\"\n",
        "    # Load original\n",
        "    original = Image.open(image_path).convert('RGB')\n",
        "    image_tensor = preprocess_image(image_path).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # A -> B\n",
        "        fake_B = netG_A2B(image_tensor)\n",
        "        # B -> A (reconstruction)\n",
        "        rec_A = netG_B2A(fake_B)\n",
        "    \n",
        "    # Convert to images\n",
        "    fake_B_img = tensor_to_image(fake_B)\n",
        "    rec_A_img = tensor_to_image(rec_A)\n",
        "    \n",
        "    # Display\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    axes[0].imshow(original)\n",
        "    axes[0].set_title('Original A')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    axes[1].imshow(fake_B_img)\n",
        "    axes[1].set_title('Translated to B')\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    axes[2].imshow(rec_A_img)\n",
        "    axes[2].set_title('Reconstructed A (B -> A)')\n",
        "    axes[2].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Cycle consistency function defined!\")\n",
        "print(\"\\nNote: This is a demonstration notebook. To use with actual data:\")\n",
        "print(\"1. Train the model on your dataset\")\n",
        "print(\"2. Load the trained weights\")\n",
        "print(\"3. Use the translation functions above\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
